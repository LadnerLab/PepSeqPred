{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6518169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "from typing import Optional, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31f531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_pt_file(pt_path: Path | str) -> torch.Tensor:\n",
    "    obj = torch.load(pt_path, map_location=\"cpu\")\n",
    "    if isinstance(obj, torch.Tensor):\n",
    "        T = obj\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported saved object in {pt_path}\")\n",
    "\n",
    "    if T.dim() != 2:\n",
    "        raise ValueError(f\"Expected 2D tensor [L, D], got shape {T.shape} in {p}\")\n",
    "\n",
    "    return T.contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd7a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_load_pt_file(Path(\"../smoketest/artifacts/pts/A0A077B1I6_CHIKV.pt\")).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc8e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = _load_pt_file(\"../smoketest/artifacts/pts/A8D0M1_ADE02.pt\")\n",
    "T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00768eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _seq_stats(T: torch.Tensor) -> Dict[str, float | int]:\n",
    "    L, D = T.shape\n",
    "    norms = torch.linalg.vector_norm(T, ord=2, dim=1)\n",
    "    return {\"L\": int(L), \"D\": int(D), \n",
    "            \"norm_min\": float(norms.min()), \n",
    "            \"norm_max\": float(norms.max()), \n",
    "            \"norms_mean\": float(norms.mean()), \n",
    "            \"norms_std\": float(norms.std(unbiased=False))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9aebdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_stats = _seq_stats(T1)\n",
    "T1_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f600b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_summary(per_seq_dir: Path | str, out_csv: Path | str) -> None:\n",
    "    rows = []\n",
    "    for pt in sorted(per_seq_dir.glob(\"*.pt\")):\n",
    "        try:\n",
    "            T = _load_pt_file(pt)\n",
    "            s = _seq_stats(T)\n",
    "            s[\"file\"] = str(pt)\n",
    "            s[\"id\"] = pt.stem\n",
    "            rows.append(s)\n",
    "        except Exception as e:\n",
    "            rows.append({\"file\": str(pt), \"id\": pt.stem, \"error\": str(e)})\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote summary to {out_csv} with {len(df)} rows\")\n",
    "    print(df.head().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8a4427",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_summary(Path(\"../smoketest/artifacts/pts\"), Path(\"../smoketest/artifacts/analysis.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038da802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmd_residue_norms(pt_file: Path | str, export_csv: Optional[Path | str] = None) -> None:\n",
    "    T = _load_pt_file(pt_file)\n",
    "    norms = torch.linalg.vector_norm(T, ord=2, dim=1).numpy()\n",
    "    df = pd.DataFrame({\"i\": np.arange(len(norms), dtype=int), \"l2_norm\": norms})\n",
    "    if export_csv:\n",
    "        df.to_csv(export_csv, index=False)\n",
    "        print(f\"Wrote residue norms to {export_csv}  |  L={len(norms)}\")\n",
    "    else:\n",
    "        print(df.head(10).to_string(index=False))\n",
    "        print(f\"   L={len(norms)}  |  mean={norms.mean():.3f}  |  std={norms.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e7c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_seq_dir = Path(\"../smoketest/artifacts/pts\")\n",
    "for pt in sorted(per_seq_dir.glob(\"*.pt\")):\n",
    "    cmd_residue_norms(pt)#, export_csv=Path(f\"./smoketest/artifacts/pts/norms/{pt.stem}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a771261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine similarity\n",
    "def _cos(a: torch.Tensor, b: torch.Tensor) -> float:\n",
    "    a, b = a.float(), b.float()\n",
    "    a_n = torch.linalg.vector_norm(a)\n",
    "    b_n = torch.linalg.vector_norm(b)\n",
    "    if a_n == 0 or b_n == 0:\n",
    "        return float(\"NaN\")\n",
    "    return float((a @ b) / (a_n * b_n))\n",
    "\n",
    "def cos_similarity(T1: torch.Tensor, T2: torch.Tensor, i1: int, i2: int) -> None:\n",
    "    if not (0 <= i1 < T1.shape[0]) or not (0 <= i2 < T2.shape[0]):\n",
    "        raise IndexError(f\"Indices out of range\\n   T1={T1.shape[0]}, i1={i1}\\n   T2={T2.shape[0]}, i2={i2}\")\n",
    "    sim = _cos(T1[i1], T2[i2])\n",
    "    print(f\"cos(T1[{i1}], T2[{i2}])={sim:.6}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7400f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = _load_pt_file(Path(\"../smoketest/artifacts/pts/A8D0M1_ADE02.pt\"))\n",
    "T2 = _load_pt_file(Path(\"../smoketest/artifacts/pts/J9Z4E7_9ADEN.pt\"))\n",
    "T1_rows = T1.shape[0]\n",
    "T2_rows = T2.shape[0]\n",
    "limit = T1_rows if T1_rows < T2_rows else T2_rows\n",
    "for i in range(limit):\n",
    "    for j in range(limit):\n",
    "        cos_similarity(T1, T2, i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca57d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_seq = _load_pt_file(Path(\"../tests/smoketest/artifacts/pts/A0A077B1I6_CHIKV.pt\"))\n",
    "long_seq[2473]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82de098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bp3_long_seq = torch.load(Path(\"../../data/7lj4_B.pt\"))\n",
    "bp3_long_seq = bp3_long_seq[\"representations\"][33]\n",
    "bp3_long_seq.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
