{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6518169",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "import random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Dict\n",
    "import torch.serialization as ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a37e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.width\", 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35215c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMB_DIR = Path(\"../localdata/sample/embeddings\")\n",
    "LABELS_PT = Path(\"../localdata/sample/labels/labels_single.pt\")\n",
    "META_TSV = Path(\"../localdata/sample/sample_meta.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cf73bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = torch.load(LABELS_PT, map_location=\"cpu\", weights_only=False)\n",
    "labels_by_id = payload[\"labels\"]\n",
    "label_ids = set(labels_by_id.keys())\n",
    "emb_by_id = {p.stem: p for p in EMB_DIR.glob(\"*.pt\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a2d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_ids = sorted(label_ids & set(emb_by_id.keys()))\n",
    "missing_emb = sorted(label_ids - set(emb_by_id.keys()))\n",
    "extra_emb = sorted(set(emb_by_id.keys()) - label_ids)\n",
    "\n",
    "print(f\"label IDs: {len(label_ids)}\")\n",
    "print(f\"embedding files: {len(emb_by_id)}\")\n",
    "print(f\"matched: {len(matched_ids)}\")\n",
    "print(f\"missing embeddings for labels: {len(missing_emb)}\")\n",
    "print(f\"extra embeddings not in labels: {len(extra_emb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92fdba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_emb_paths = [emb_by_id[pid] for pid in matched_ids]\n",
    "selected_labels = {pid: labels_by_id[pid] for pid in matched_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cde186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pid(fullname: str) -> str:\n",
    "    m = re.match(r\"^ID=([^\\s])\", fullname.strip())\n",
    "    return m.group(1) if m else \"\"\n",
    "\n",
    "def load_emb(pt_path: Path) -> torch.Tensor:\n",
    "    x = torch.load(pt_path, map_location=\"cpu\", weights_only=True)\n",
    "    if not isinstance(x, torch.Tensor) or x.dim() != 2:\n",
    "        raise ValueError(f\"Bad embedding in {pt_path}: type={type(pt_path)}, shape={getattr(x, 'shape', None)}\")\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358e991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show one random protein end-to-end\n",
    "pid = random.choice(matched_ids)\n",
    "x = torch.load(emb_by_id[pid], map_location=\"cpu\", weights_only=True)   # (L, D)\n",
    "y = selected_labels[pid]                                                 # (L, 3)\n",
    "\n",
    "print(\"protein_id:\", pid)\n",
    "print(\"embedding shape:\", tuple(x.shape), \"dtype:\", x.dtype)\n",
    "print(\"label shape:\", tuple(y.shape), \"dtype:\", y.dtype)\n",
    "\n",
    "print(\"\\nEmbedding sample (first 3 residues, first 8 dims):\")\n",
    "print(x[:3, :8])\n",
    "\n",
    "print(\"\\nLabel sample (first 12 residues) [def, unc, not]:\")\n",
    "print(y[:12])\n",
    "\n",
    "print(\"\\nClass counts for this protein:\")\n",
    "print({\n",
    "    \"def\": int(y[:,0].sum().item()),\n",
    "    \"unc\": int(y[:,1].sum().item()),\n",
    "    \"not\": int(y[:,2].sum().item()),\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
